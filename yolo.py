import cv2
import torch
import numpy as np
from ultralytics import YOLO
import utils
import matplotlib as plt
import os
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit

#-------------YOlO->ONNX->tensorRT
def convert_yolo_to_onnx(model_path, onnx_path="yolo_model.onnx", input_size=(1, 3, 640, 640)):
    """ PyTorch YOLO ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ """
    model = torch.load(model_path, map_location="cuda")  # ëª¨ë¸ ë¡œë“œ
    model.eval()  # ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •

    # ë”ë¯¸ ì…ë ¥ (YOLOëŠ” 640x640 ê¸°ë³¸)
    dummy_input = torch.randn(*input_size).cuda()

    # ONNX ë³€í™˜
    torch.onnx.export(
        model, 
        dummy_input, 
        onnx_path, 
        opset_version=11, 
        input_names=["input"], 
        output_names=["output"]
    )

    print(f"âœ… ONNX ë³€í™˜ ì™„ë£Œ: {onnx_path}")
    return onnx_path

def convert_onnx_to_trt(onnx_path, trt_path="yolo_model.trt", fp16=True):
    """ ONNX ëª¨ë¸ì„ TensorRTë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ """
    fp16_flag = "--fp16" if fp16 else ""
    
    # TensorRTcond ë³€í™˜ ì‹¤í–‰
    command = f"trtexec --onnx={onnx_path} --saveEngine={trt_path} {fp16_flag}"
    os.system(command)
    
    print(f"âœ… TensorRT ë³€í™˜ ì™„ë£Œ: {trt_path}")
    return trt_path

def convert_yolo_to_trt(pytorch_model_path, onnx_path="yolo_model.onnx", trt_path="yolo_model.trt", fp16=True):
    """ PyTorch YOLO â†’ ONNX â†’ TensorRT ë³€í™˜ì„ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ """
    convert_yolo_to_onnx(pytorch_model_path, onnx_path)
    convert_onnx_to_trt(onnx_path, trt_path, fp16)
    print(f"ğŸš€ ìµœì í™” ì™„ë£Œ! TensorRT ëª¨ë¸ ì €ì¥ë¨: {trt_path}")
    return trt_path



#---------------YOLO----------------
def load_trt_engine(engine_path):
    """TensorRT ì—”ì§„ ë¡œë“œ"""
    with open(engine_path, "rb") as f:
        runtime = trt.Runtime(TRT_LOGGER)
        return runtime.deserialize_cuda_engine(f.read())

def load_model(engine_path="data/yolo_model.trt"):
    """YOLO TensorRT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
    engine = load_trt_engine(engine_path)
    context = engine.create_execution_context()
    return engine, context


TRT_LOGGER = trt.Logger(trt.Logger.WARNING)

def letterbox(image, new_shape=(640, 640), color=(114, 114, 114)):
    """ ì´ë¯¸ì§€ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ YOLO ì…ë ¥ í¬ê¸°(640x640)ë¡œ íŒ¨ë”© """
    shape = image.shape[:2]  # í˜„ì¬ (H, W)
    ratio = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  # í¬ê¸° ë¹„ìœ¨ ìœ ì§€
    new_unpad = (int(round(shape[1] * ratio)), int(round(shape[0] * ratio)))  # ìƒˆë¡œìš´ í¬ê¸°
    image_resized = cv2.resize(image, new_unpad, interpolation=cv2.INTER_LINEAR)

    # íŒ¨ë”© ì¶”ê°€ (ì¢Œìš°/ìƒí•˜)
    dw = (new_shape[1] - new_unpad[0]) / 2  # width padding
    dh = (new_shape[0] - new_unpad[1]) / 2  # height padding
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))

    # íŒ¨ë”© ì ìš©
    image_padded = cv2.copyMakeBorder(image_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
    return image_padded

def postprocess(output, img_shape, conf_thres=0.5, iou_thres=0.4):
    """ YOLO TensorRT í›„ì²˜ë¦¬: ë°”ìš´ë”© ë°•ìŠ¤ & NMS ì ìš© """

    num_detections = output.shape[0]  # ê°ì§€ëœ ê°ì²´ ê°œìˆ˜
    bboxes = []
    scores = []
    class_ids = []

    for i in range(num_detections):
        confidence = output[i, 4]  # ê°ì²´ ì‹ ë¢°ë„
        if confidence < conf_thres:
            continue  # ì‹ ë¢°ë„ ë‚®ìœ¼ë©´ ë¬´ì‹œ

        # í´ë˜ìŠ¤ í™•ë¥  ì¤‘ ê°€ì¥ ë†’ì€ ê²ƒ ì°¾ê¸°
        class_probs = output[i, 5:]  # í´ë˜ìŠ¤ í™•ë¥  (80ê°œ)
        class_id = np.argmax(class_probs)
        score = class_probs[class_id] * confidence  # ìµœì¢… ì‹ ë¢°ë„

        if score < conf_thres:
            continue

        # YOLOëŠ” ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³€í™˜
        x_center, y_center, w, h = output[i, :4] * np.array([img_shape[1], img_shape[0], img_shape[1], img_shape[0]])
        x1 = int(x_center - w / 2)
        y1 = int(y_center - h / 2)
        x2 = int(x_center + w / 2)
        y2 = int(y_center + h / 2)

        bboxes.append([x1, y1, x2, y2])
        scores.append(float(score))
        class_ids.append(class_id)

    # NMS ì ìš©
    indices = cv2.dnn.NMSBoxes(bboxes, scores, conf_thres, iou_thres)
    final_bboxes = [bboxes[i] for i in indices.flatten()]
    final_scores = [scores[i] for i in indices.flatten()]
    final_class_ids = [class_ids[i] for i in indices.flatten()]

    return final_bboxes, final_scores, final_class_ids
class DetectionResult:
    """YOLO results ê°ì²´ì²˜ëŸ¼ ë™ì‘í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, bboxes, scores, class_ids):
        self.boxes = np.array(bboxes, dtype=np.float32)  # ë°”ìš´ë”© ë°•ìŠ¤ (xyxy)
        self.scores = np.array(scores, dtype=np.float32)  # ì‹ ë¢°ë„ ì ìˆ˜
        self.class_ids = np.array(class_ids, dtype=np.int32)  # í´ë˜ìŠ¤ ID

    def __getitem__(self, idx):
        """ ë¦¬ìŠ¤íŠ¸ì²˜ëŸ¼ ì¸ë±ì‹± ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì • """
        return (self.boxes[idx], self.scores[idx], self.class_ids[idx])

    def __len__(self):
        return len(self.boxes)

def detect(engine, context, image):
    """ TensorRT ê¸°ë°˜ YOLO ì¶”ë¡  (ê¸°ì¡´ YOLO results ê°ì²´ì²˜ëŸ¼ ì¶œë ¥) """

    if isinstance(image, str):  # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì…ë ¥
        image = cv2.imread(image)

    img_shape = image.shape[:2]  # (H, W) ì €ì¥
    image_padded = letterbox(image)  # YOLO ì…ë ¥ í¬ê¸° ë§ì¶¤
    image_padded = image_padded.astype(np.float32) / 255.0  # ì •ê·œí™”
    image_padded = np.transpose(image_padded, (2, 0, 1))  # (H, W, C) â†’ (C, H, W)
    image_padded = np.expand_dims(image_padded, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

    # TensorRT ì‹¤í–‰
    d_input = cuda.mem_alloc(image_padded.nbytes)
    d_output = cuda.mem_alloc(1000000)  # ì¶©ë¶„í•œ í¬ê¸° í™•ë³´ (ì¶œë ¥ í¬ê¸°ì— ë§ê²Œ ì„¤ì • í•„ìš”)
    bindings = [int(d_input), int(d_output)]
    stream = cuda.Stream()
    cuda.memcpy_htod_async(d_input, image_padded, stream)
    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)
    cuda.memcpy_dtoh_async(image_padded, d_output, stream)
    stream.synchronize()

    # í›„ì²˜ë¦¬ ì ìš©
    final_bboxes, final_scores, final_class_ids = postprocess(image_padded, img_shape)

    # ê¸°ì¡´ YOLO `results` ê°ì²´ì²˜ëŸ¼ ë³€í™˜
    results = [DetectionResult(final_bboxes, final_scores, final_class_ids)]

    return results  # ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ë˜ë„ë¡ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ë°˜í™˜





#--------ê± í…ŒìŠ¤íŠ¸ìš©-----------



def main():
    model_path = "best.pt"
    image_path = "test.jpg"

    model = YOLO(model_path)  # YOLO ëª¨ë¸ ë¡œë“œ
    results = model(image_path)  # ê°ì²´ íƒì§€ ì‹¤í–‰

    print(results)  # ê²°ê³¼ ì¶œë ¥ (ë””ë²„ê¹…ìš©)

if __name__ == "__main__":
    main()

# -----ì°½ê³ ---------

def draw_bbox(model, image, show = False):
    """
    YOLO ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ê³  ê²°ê³¼ë¥¼ ì¶œë ¥.
    
    Parameters
    ----------
    model : YOLO ê°ì²´
    image : np.ndarray ë˜ëŠ” str
        - np.ndarray: OpenCV ì´ë¯¸ì§€ (BGR)
        - str: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    """
    if isinstance(image, str):
        img = cv2.imread(image)  # íŒŒì¼ ê²½ë¡œì¼ ê²½ìš° ì½ê¸°
    elif isinstance(image, np.ndarray):
        img = image.copy()  # numpy ë°°ì—´ì¼ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
    else:
        raise ValueError("imageëŠ” íŒŒì¼ ê²½ë¡œë‚˜ numpy ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    results = model.predict(img)  # YOLO ì‹¤í–‰
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    
    ##save path
    save_path = os.path.dirname(os.path.abspath(__file__))
    cv2.imwrite(save_path, img)
    print(f"âœ… Bounding box image saved as: {save_path}")

        # ğŸ”¥ Matplotlibìœ¼ë¡œ ì´ë¯¸ì§€ í‘œì‹œ (ì„ íƒ)
    if show:
        plt.figure(figsize=(6, 6))
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title("YOLO Detection")
        plt.axis("off")
        plt.show()