import cv2
import torch
import numpy as np
from ultralytics import YOLO
import utils
import matplotlib as plt
import os
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit



#---------------ì „ì—­ë³€ìˆ˜ëª¨ìŒ
class Config:
    current_path = os.path.dirname(os.path.abspath(__file__))
    onnx_path=os.path.join(current_path, "yolo", "yolo_model.onnx")
    model_path = os.path.join(current_path, "yolo", "best.pt")
    trt_path=os.path.join(current_path, "yolo", "yolo_model.trt")



#---------------YOLO----------------
def load_trt_engine(engine_path):
    """TensorRT ì—”ì§„ ë¡œë“œ"""
    with open(engine_path, "rb") as f:
        runtime = trt.Runtime(TRT_LOGGER)
        return runtime.deserialize_cuda_engine(f.read())

def load_model(model_path=Config.model_path, trt_path=Config.trt_path):
    """YOLO TensorRT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
    trt_path = Config.trt_path
    engine = load_trt_engine(trt_path)
    context = engine.create_execution_context()
    return engine, context


TRT_LOGGER = trt.Logger(trt.Logger.WARNING)

# def letterbox(image, new_shape=(640, 640), color=(114, 114, 114)):
#     """ ì´ë¯¸ì§€ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ YOLO ì…ë ¥ í¬ê¸°(640x640)ë¡œ íŒ¨ë”© """
#     shape = image.shape[:2]  # í˜„ì¬ (H, W)
#     ratio = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  # í¬ê¸° ë¹„ìœ¨ ìœ ì§€
#     new_unpad = (int(round(shape[1] * ratio)), int(round(shape[0] * ratio)))  # ìƒˆë¡œìš´ í¬ê¸°
#     image_resized = cv2.resize(image, new_unpad, interpolation=cv2.INTER_LINEAR)

#     # íŒ¨ë”© ì¶”ê°€ (ì¢Œìš°/ìƒí•˜)
#     dw = (new_shape[1] - new_unpad[0]) / 2  # width padding
#     dh = (new_shape[0] - new_unpad[1]) / 2  # height padding
#     top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
#     left, right = int(round(dw - 0.1)), int(round(dw + 0.1))

#     # íŒ¨ë”© ì ìš©
#     image_padded = cv2.copyMakeBorder(image_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
#     image_padded = image_padded.astype(np.float32)
#     image_padded = np.ascontiguousarray(image_padded)


#     print("C_CONTIGUOUS:", image_padded.flags['C_CONTIGUOUS'])
#     print("Shape:", image_padded.shape)
#     print("Dtype:", image_padded.dtype)


#     return image_padded


def letterbox(image, new_shape=(640, 640), color=(114, 114, 114)):
    """ ì´ë¯¸ì§€ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ YOLO ì…ë ¥ í¬ê¸°(640x640)ë¡œ íŒ¨ë”© """
    shape = image.shape[:2]  # í˜„ì¬ (H, W)
    ratio = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  # í¬ê¸° ë¹„ìœ¨ ìœ ì§€
    new_unpad = (int(round(shape[1] * ratio)), int(round(shape[0] * ratio)))  # ìƒˆë¡œìš´ í¬ê¸°
    image_resized = cv2.resize(image, new_unpad, interpolation=cv2.INTER_LINEAR)

    # íŒ¨ë”© ì¶”ê°€ (ì¢Œìš°/ìƒí•˜)
    dw = (new_shape[1] - new_unpad[0]) / 2  # width padding
    dh = (new_shape[0] - new_unpad[1]) / 2  # height padding
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))

    # íŒ¨ë”© ì ìš©
    image_padded = cv2.copyMakeBorder(image_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
    image_padded = image_padded.astype(np.float32)

     # (H, W, C) â†’ (C, XH, W) ë³€í™˜ í•„ìš”í•  ê²½ìš° ìˆ˜í–‰
    if image_padded.shape[-1] == 3:  # ë§ˆì§€ë§‰ ì°¨ì›ì´ 3ì´ë©´ ë³€í™˜ í•„ìš”
        image_padded = np.transpose(image_padded, (2, 0, 1))  # (H, W, C) â†’ (C, H, W)


    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (YOLO ëª¨ë¸ì´ (1, C, H, W) í˜•ì‹ì„ ê¸°ëŒ€í•  ìˆ˜ë„ ìˆìŒ)
    image_padded = np.expand_dims(image_padded, axis=0)  # (C, H, W) â†’ (1, C, H, W)

    # ë©”ëª¨ë¦¬ ì—°ì†ì„±ì„ ë³´ì¥
    image_padded = np.ascontiguousarray(image_padded)

    print("C_CONTIGUOUS:", image_padded.flags['C_CONTIGUOUS'])
    print("Shape:", image_padded.shape)  # (1, 3, 640, 640) í˜•íƒœê°€ ë˜ì–´ì•¼ í•¨
    print("Dtype:", image_padded.dtype)

    return image_padded


def postprocess(output, img_shape, conf_thres=0.5, iou_thres=0.4):
    """ YOLO TensorRT í›„ì²˜ë¦¬: ë°”ìš´ë”© ë°•ìŠ¤ & NMS ì ìš© """
    print("Output shape before processing:", output.shape)

    #outputì—ì„œ ì²« ë²ˆì§¸ ì°¨ì›ì„ ì œê±°
    #ë‘ ë²ˆì§¸ ì°¨ì›(60)ì˜ í´ë˜ìŠ¤ í™•ë¥ ì— ì ‘ê·¼(ì–´ì°¨í”¼ binary íƒìƒ‰ì´ë¼ í´ë˜ìŠ¤ëŠ” 1ê°œë°–ì— ì—†ìŒ)

    num_detections = output.shape[0]  # ê°ì§€ëœ ê°ì²´ ê°œìˆ˜
    bboxes = []
    scores = []
    class_ids = []

    for i in range(num_detections):
        confidence = float(output[i, 4])  # ê°ì²´ ì‹ ë¢°ë„
        if confidence < conf_thres:
            continue  # ì‹ ë¢°ë„ ë‚®ìœ¼ë©´ ë¬´ì‹œ

        # í´ë˜ìŠ¤ í™•ë¥  ì¤‘ ê°€ì¥ ë†’ì€ ê²ƒ ì°¾ê¸°
        class_probs = output[i, 5:]  # í´ë˜ìŠ¤ í™•ë¥  (80ê°œ)
        class_id = np.argmax(class_probs)
        score = class_probs[class_id] * confidence  # ìµœì¢… ì‹ ë¢°ë„

        if score < conf_thres:
            continue

        # YOLOëŠ” ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³€í™˜
        x_center, y_center, w, h = output[i, :4] * np.array([img_shape[1], img_shape[0], img_shape[1], img_shape[0]])
        x1 = int(x_center - w / 2)
        y1 = int(y_center - h / 2)
        x2 = int(x_center + w / 2)
        y2 = int(y_center + h / 2)

        bboxes.append([x1, y1, x2, y2])
        scores.append(float(score))
        class_ids.append(class_id)

    # NMS ì ìš©
    indices = cv2.dnn.NMSBoxes(bboxes, scores, conf_thres, iou_thres)
    final_bboxes = [bboxes[i] for i in indices.flatten()]
    final_scores = [scores[i] for i in indices.flatten()]
    final_class_ids = [class_ids[i] for i in indices.flatten()]

    return final_bboxes, final_scores, final_class_ids


class DetectionResult:
    """YOLO results ê°ì²´ì²˜ëŸ¼ ë™ì‘í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, bboxes, scores, class_ids):
        self.boxes = np.array(bboxes, dtype=np.float32)  # ë°”ìš´ë”© ë°•ìŠ¤ (xyxy)
        self.scores = np.array(scores, dtype=np.float32)  # ì‹ ë¢°ë„ ì ìˆ˜
        self.class_ids = np.array(class_ids, dtype=np.int32)  # í´ë˜ìŠ¤ ID

    def __getitem__(self, idx):
        """ ë¦¬ìŠ¤íŠ¸ì²˜ëŸ¼ ì¸ë±ì‹± ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì • """
        return (self.boxes[idx], self.scores[idx], self.class_ids[idx])

    def __len__(self):
        return len(self.boxes)

def detect(engine, context, image):
    """ TensorRT ê¸°ë°˜ YOLO ì¶”ë¡  (ê¸°ì¡´ YOLO results ê°ì²´ì²˜ëŸ¼ ì¶œë ¥) """

    if isinstance(image, str):  # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì…ë ¥
        image = cv2.imread(image)

    img_shape = image.shape[:2]  # (H, W) ì €ì¥
    image_padded = letterbox(image)  # YOLO ì…ë ¥ í¬ê¸° ë§ì¶¤
    image_padded = image_padded.astype(np.float32) / 255.0  # ì •ê·œí™”

    print("Final shape before CUDA:", image_padded.shape)  # âœ… (1, 3, 640, 640) í™•ì¸

    # TensorRT ì‹¤í–‰
    d_input = cuda.mem_alloc(image_padded.nbytes)

    # âœ… ì—”ì§„ì—ì„œ ì¶œë ¥ í…ì„œ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
    output_shape = context.get_binding_shape(1)  # 1ë²ˆ ì¸ë±ìŠ¤ê°€ ì¶œë ¥ í…ì„œ
    output_size = np.prod(output_shape) * np.dtype(np.float32).itemsize  # ì´ ë°”ì´íŠ¸ ìˆ˜ ê³„ì‚°
    d_output = cuda.mem_alloc(int(output_size))  # âœ… ì •í™•í•œ í¬ê¸° ì„¤ì •

    bindings = [int(d_input), int(d_output)]
    stream = cuda.Stream()

    # ì…ë ¥ ë°ì´í„° ë³µì‚¬
    cuda.memcpy_htod_async(d_input, image_padded, stream)
    context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)

    # âœ… ì¶œë ¥ ë°ì´í„°ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ë°°ì—´ ìƒì„±
    h_output = np.empty(output_shape, dtype=np.float32)  # ëª¨ë¸ ì¶œë ¥ í¬ê¸°ì™€ ë™ì¼í•œ í˜•íƒœ

    # âœ… GPU â†’ CPUë¡œ ì¶œë ¥ ë°ì´í„° ë³µì‚¬
    cuda.memcpy_dtoh_async(h_output, d_output, stream)
    stream.synchronize()

    # âœ… í›„ì²˜ë¦¬ í•¨ìˆ˜ì—ì„œ h_outputì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
    final_bboxes, final_scores, final_class_ids = postprocess(h_output, img_shape)

    # ê¸°ì¡´ YOLO `results` ê°ì²´ì²˜ëŸ¼ ë³€í™˜
    results = [DetectionResult(final_bboxes, final_scores, final_class_ids)]

    return results  # ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ë˜ë„ë¡ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ë°˜í™˜





#--------ê± í…ŒìŠ¤íŠ¸ìš©-----------



def main():
    model_path = "best.pt"
    image_path = "test.jpg"

    model = YOLO(model_path)  # YOLO ëª¨ë¸ ë¡œë“œ
    results = model(image_path)  # ê°ì²´ íƒì§€ ì‹¤í–‰

    print(results)  # ê²°ê³¼ ì¶œë ¥ (ë””ë²„ê¹…ìš©)

if __name__ == "__main__":
    main()

# -----ì°½ê³ ---------

def draw_bbox(model, image, show = False):
    """
    YOLO ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ê³  ê²°ê³¼ë¥¼ ì¶œë ¥.
    
    Parameters
    ----------
    model : YOLO ê°ì²´
    image : np.ndarray ë˜ëŠ” str
        - np.ndarray: OpenCV ì´ë¯¸ì§€ (BGR)
        - str: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    """
    if isinstance(image, str):
        img = cv2.imread(image)  # íŒŒì¼ ê²½ë¡œì¼ ê²½ìš° ì½ê¸°
    elif isinstance(image, np.ndarray):
        img = image.copy()  # numpy ë°°ì—´ì¼ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
    else:
        raise ValueError("imageëŠ” íŒŒì¼ ê²½ë¡œë‚˜ numpy ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    results = model.predict(img)  # YOLO ì‹¤í–‰
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    
    ##save path
    save_path = os.path.dirname(os.path.abspath(__file__))
    cv2.imwrite(save_path, img)
    print(f"âœ… Bounding box image saved as: {save_path}")

        # ğŸ”¥ Matplotlibìœ¼ë¡œ ì´ë¯¸ì§€ í‘œì‹œ (ì„ íƒ)
    if show:
        plt.figure(figsize=(6, 6))
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title("YOLO Detection")
        plt.axis("off")
        plt.show()