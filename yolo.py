import cv2
import torch
import numpy as np
from ultralytics import YOLO
import utils
import matplotlib as plt
import os
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
import scipy.special  
from scipy.special import expit

#-----------------ultralytics ìšœë¡œ ê°ì²´ì²˜ëŸ¼ ë³€í™˜í•˜ëŠ”ê±°
class Boxes:
    """ ë°”ìš´ë”© ë°•ìŠ¤ ë°ì´í„°ë¥¼ YOLO í˜•ì‹ê³¼ ìœ ì‚¬í•˜ê²Œ ê°ì‹¸ëŠ” í´ë˜ìŠ¤ """
    def __init__(self, bboxes, scores, cls):
        self.xyxy = np.array(bboxes)  # ì¢Œí‘œ ì •ë³´
        self.scores = np.array(scores)  # ì‹ ë¢°ë„ ì ìˆ˜
        self.cls = np.array(cls)  # í´ë˜ìŠ¤ ID

class DetectionResult:
    """ YOLO í˜•ì‹ê³¼ í˜¸í™˜ë˜ë„ë¡ boxes ì†ì„±ì„ í¬í•¨í•œ ê²°ê³¼ ê°ì²´ """
    def __init__(self, bboxes, scores, cls):
        self.boxes = Boxes(bboxes, scores, cls)  # Boxes ê°ì²´ë¡œ ê°ì‹¸ê¸°




#---------------ì „ì—­ë³€ìˆ˜ëª¨ìŒ
class Config:
    current_path = os.path.dirname(os.path.abspath(__file__))
    onnx_path=os.path.join(current_path, "yolo", "yolo_model.onnx")
    model_path = os.path.join(current_path, "yolo", "best.pt")
    trt_path=os.path.join(current_path, "yolo", "yolo_model.trt")



#---------------YOLO----------------
def load_trt_engine(engine_path):
    """TensorRT ì—”ì§„ ë¡œë“œ"""
    with open(engine_path, "rb") as f:
        runtime = trt.Runtime(TRT_LOGGER)
        return runtime.deserialize_cuda_engine(f.read())

def load_model(model_path=Config.model_path, trt_path=Config.trt_path):
    """YOLO TensorRT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"""
    trt_path = Config.trt_path
    engine = load_trt_engine(trt_path)
    context = engine.create_execution_context()
    return engine, context


TRT_LOGGER = trt.Logger(trt.Logger.WARNING)


def letterbox(image, new_shape=(640, 640), color=(114, 114, 114)):
    """ ì´ë¯¸ì§€ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ YOLO ì…ë ¥ í¬ê¸°(640x640)ë¡œ íŒ¨ë”© """
    shape = image.shape[:2]  # í˜„ì¬ (H, W)
    ratio = min(new_shape[0] / shape[0], new_shape[1] / shape[1])  # í¬ê¸° ë¹„ìœ¨ ìœ ì§€
    new_unpad = (int(round(shape[1] * ratio)), int(round(shape[0] * ratio)))  # ìƒˆë¡œìš´ í¬ê¸°
    image_resized = cv2.resize(image, new_unpad, interpolation=cv2.INTER_LINEAR)

    # íŒ¨ë”© ì¶”ê°€ (ì¢Œìš°/ìƒí•˜)
    dw = (new_shape[1] - new_unpad[0]) / 2  # width padding
    dh = (new_shape[0] - new_unpad[1]) / 2  # height padding
    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))

    # íŒ¨ë”© ì ìš©
    image_padded = cv2.copyMakeBorder(image_resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)
    image_padded = image_padded.astype(np.float32)

     # (H, W, C) â†’ (C, XH, W) ë³€í™˜ í•„ìš”í•  ê²½ìš° ìˆ˜í–‰
    if image_padded.shape[-1] == 3:  # ë§ˆì§€ë§‰ ì°¨ì›ì´ 3ì´ë©´ ë³€í™˜ í•„ìš”
        image_padded = np.transpose(image_padded, (2, 0, 1))  # (H, W, C) â†’ (C, H, W)


    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (YOLO ëª¨ë¸ì´ (1, C, H, W) í˜•ì‹ì„ ê¸°ëŒ€í•  ìˆ˜ë„ ìˆìŒ)
    image_padded = np.expand_dims(image_padded, axis=0)  # (C, H, W) â†’ (1, C, H, W)

    # ë©”ëª¨ë¦¬ ì—°ì†ì„±ì„ ë³´ì¥
    image_padded = np.ascontiguousarray(image_padded)

    print("C_CONTIGUOUS:", image_padded.flags['C_CONTIGUOUS'])
    print("Shape:", image_padded.shape)  # (1, 3, 640, 640) í˜•íƒœê°€ ë˜ì–´ì•¼ í•¨
    print("Dtype:", image_padded.dtype)

    return image_padded


def postprocess(output, img_shape, conf_thres=0.2, iou_thres=0.4):
    """ YOLO TensorRT í›„ì²˜ë¦¬: ë°”ìš´ë”© ë°•ìŠ¤ & NMS ì ìš© """
    print("Output shape before processing:", output.shape)
    
    # 1. ë°°ì¹˜ ì°¨ì› ì œê±° (ì˜ˆ: (1, 65, 80, 80) -> (65, 80, 80))
    if output.shape[0] == 1:
        output = np.squeeze(output, axis=0)
    print("After squeeze:", output.shape)
    
    # 2. (65, 80, 80) â†’ (80, 80, 65) ë³€í™˜
    output = output.transpose(1, 2, 0)
    print("After transpose:", output.shape)
    
    # 3. (80, 80, 65) â†’ (6400, 65)ë¡œ ë³€í™˜
    output = output.reshape(-1, output.shape[-1])
    print("After reshape:", output.shape)

    num_detections = output.shape[0]  # ì´ detection ìˆ˜
    bboxes = []
    scores = []
    class_ids = []
    
    for i in range(num_detections):
        detection = output[i]

        confidence = float(scipy.special.expit(detection[4]))  # objectness score
        if confidence < conf_thres:
            continue

        class_probs = scipy.special.expit(detection[5:]) 
        class_id = int(np.argmax(class_probs))
        score = float(class_probs[class_id]) * confidence
        if score < conf_thres:
            continue

        x_center, y_center, w, h = detection[0:4] * np.array([img_shape[1], img_shape[0], img_shape[1], img_shape[0]])

        print("Detection values:", detection[0:4])  # ì¶œë ¥ ê°’ í™•ì¸


        x1 = int(x_center - w / 2)  # x1 = center - width/2
        y1 = int(y_center - h / 2)  # y1 = center - height/2
        x2 = int(x_center + w / 2)  # x2 = center + width/2
        y2 = int(y_center + h / 2)  # y2 = center + height/2
  
        if x1 < 0: x1 = 0
        if y1 < 0: y1 = 0
        if x2 > img_shape[1]: x2 = img_shape[1]
        if y2 > img_shape[0]: y2 = img_shape[0]

        bboxes.append([x1, y1, x2, y2])
        scores.append(score)
        class_ids.append(class_id)
    
    # 5. NMS ì ìš©
    indices = cv2.dnn.NMSBoxes(bboxes, scores, conf_thres, iou_thres)
    if len(indices) > 0:
        final_bboxes = [bboxes[i] for i in indices.flatten()]
        final_scores = [scores[i] for i in indices.flatten()]
        final_class_ids = [class_ids[i] for i in indices.flatten()]
    else:
        final_bboxes, final_scores, final_class_ids = [], [], []

    return final_bboxes, final_scores, final_class_ids


def detect(engine, context, image):
    """ TensorRT ê¸°ë°˜ YOLO ì¶”ë¡  (ê¸°ì¡´ YOLO results ê°ì²´ì²˜ëŸ¼ ì¶œë ¥) """

    print("DEBUG: detect() ì‹œì‘")

    if isinstance(image, str):  # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì…ë ¥
        image = cv2.imread(image)

    img_shape = image.shape[:2]  # (H, W) ì €ì¥
    print("DEBUG: Image shape:", img_shape)

    image_padded = letterbox(image)  # YOLO ì…ë ¥ í¬ê¸° ë§ì¶¤
    image_padded = image_padded.astype(np.float32) / 255.0  # ì •ê·œí™”

    print("Final shape before CUDA:", image_padded.shape)  # âœ… (1, 3, 640, 640) í™•ì¸

    # TensorRT ì‹¤í–‰
    d_input = cuda.mem_alloc(image_padded.nbytes)
    print("DEBUG: d_input ë©”ëª¨ë¦¬ í• ë‹¹ ì™„ë£Œ")

    # âœ… ì—”ì§„ì—ì„œ ì¶œë ¥ í…ì„œ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
    output_shape = context.get_binding_shape(1)  # 1ë²ˆ ì¸ë±ìŠ¤ê°€ ì¶œë ¥ í…ì„œ
    output_size = np.prod(output_shape) * np.dtype(np.float32).itemsize  # ì´ ë°”ì´íŠ¸ ìˆ˜ ê³„ì‚°
    print("DEBUG: Output shape:", output_shape)

    d_output = cuda.mem_alloc(int(output_size))  # âœ… ì •í™•í•œ í¬ê¸° ì„¤ì •
    print("DEBUG: d_output ë©”ëª¨ë¦¬ í• ë‹¹ ì™„ë£Œ")

    bindings = [int(d_input), int(d_output)]
    stream = cuda.Stream()
    print("DEBUG: CUDA Stream ìƒì„± ì™„ë£Œ")

    # ì…ë ¥ ë°ì´í„° ë³µì‚¬
    cuda.memcpy_htod_async(d_input, image_padded, stream)
    print("DEBUG: ì…ë ¥ ë°ì´í„° ë³µì‚¬ ì™„ë£Œ")

    # TensorRT ì‹¤í–‰
    try:
        context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)
        print("DEBUG: TensorRT ì‹¤í–‰ ì™„ë£Œ")
    except Exception as e:
        print("ERROR: TensorRT ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", str(e))
        return []

    # âœ… ì¶œë ¥ ë°ì´í„°ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ë°°ì—´ ìƒì„±
    h_output = np.empty(output_shape, dtype=np.float32)  # ëª¨ë¸ ì¶œë ¥ í¬ê¸°ì™€ ë™ì¼í•œ í˜•íƒœ
    print("DEBUG: h_output ë°°ì—´ ìƒì„± ì™„ë£Œ")

    # âœ… GPU â†’ CPUë¡œ ì¶œë ¥ ë°ì´í„° ë³µì‚¬
    cuda.memcpy_dtoh_async(h_output, d_output, stream)
    stream.synchronize()
    print("DEBUG: GPU â†’ CPU ë°ì´í„° ë³µì‚¬ ì™„ë£Œ")

    # âœ… í›„ì²˜ë¦¬ í•¨ìˆ˜ì—ì„œ h_outputì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
    final_bboxes, final_scores, final_class_ids = postprocess(h_output, img_shape)
    if not final_bboxes:
        print("DEBUG: postprocess has done, No detections found")
        return []

    # ê¸°ì¡´ YOLO `results` ê°ì²´ì²˜ëŸ¼ ë³€í™˜
    results = [DetectionResult(final_bboxes, final_scores, final_class_ids)]
    
    # âœ… ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€
    print("Detections:")
    for i in range(len(results[0].boxes.xyxy)):
        print(f"Box {i}: {results[0].boxes.xyxy[i]}, Score: {results[0].boxes.scores[i]}, Class: {results[0].boxes.cls[i]}")

    print("DEBUG: detect() ì™„ë£Œ")
    return results  # ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ë˜ë„ë¡ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ë°˜í™˜





#--------ê± í…ŒìŠ¤íŠ¸ìš©-----------



def main():
    model_path = "best.pt"
    image_path = "test.jpg"

    model = YOLO(model_path)  # YOLO ëª¨ë¸ ë¡œë“œ
    results = model(image_path)  # ê°ì²´ íƒì§€ ì‹¤í–‰

    print(results)  # ê²°ê³¼ ì¶œë ¥ (ë””ë²„ê¹…ìš©)

if __name__ == "__main__":
    main()

# -----ì°½ê³ ---------

def draw_bbox(model, image, show = False):
    """
    YOLO ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ê³  ê²°ê³¼ë¥¼ ì¶œë ¥.
    
    Parameters
    ----------
    model : YOLO ê°ì²´
    image : np.ndarray ë˜ëŠ” str
        - np.ndarray: OpenCV ì´ë¯¸ì§€ (BGR)
        - str: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    """
    if isinstance(image, str):
        img = cv2.imread(image)  # íŒŒì¼ ê²½ë¡œì¼ ê²½ìš° ì½ê¸°
    elif isinstance(image, np.ndarray):
        img = image.copy()  # numpy ë°°ì—´ì¼ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
    else:
        raise ValueError("imageëŠ” íŒŒì¼ ê²½ë¡œë‚˜ numpy ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    results = model.predict(img)  # YOLO ì‹¤í–‰
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    
    ##save path
    save_path = os.path.dirname(os.path.abspath(__file__))
    cv2.imwrite(save_path, img)
    print(f"âœ… Bounding box image saved as: {save_path}")

        # ğŸ”¥ Matplotlibìœ¼ë¡œ ì´ë¯¸ì§€ í‘œì‹œ (ì„ íƒ)
    if show:
        plt.figure(figsize=(6, 6))
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title("YOLO Detection")
        plt.axis("off")
        plt.show()