import cv2
import torch
import numpy as np
from ultralytics import YOLO
import utils
import matplotlib as plt

#---------------YOLO----------------
def load_model(model_path):
    """ í•™ìŠµëœ YOLO ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜´ """
    model = YOLO(model_path)  # YOLO ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    print(model.names)  # í´ëž˜ìŠ¤ ëª©ë¡ ì¶œë ¥
    return model

def detect(model, image):
    if isinstance(image,str):
        results = model(image)
    elif isinstance(image, np.ndarray):
        results = model.predict(image)
    else:
        raise ValueError("imageëŠ” íŒŒì¼ ê²½ë¡œë‚˜ np arrayì—¬ì•¼ í•¨.")
    for result in results:
        print(result)
    return results




def remove_redundant_boxes(results, depth_map):
    """
    YOLO íƒì§€ ê²°ê³¼ì—ì„œ ê° í´ëž˜ìŠ¤ë³„ë¡œ ê°€ìž¥ ê°€ê¹Œìš´ ë°”ìš´ë”© ë°•ìŠ¤ í•˜ë‚˜ë§Œ ë‚¨ê¹€.
    - results: YOLO íƒì§€ ê²°ê³¼ (ultralytics YOLO output)
    - depth_map: Depth ì •ë³´ê°€ í¬í•¨ëœ numpy ë°°ì—´
    ë°˜í™˜ê°’:
    - {í´ëž˜ìŠ¤ ID: ê°€ìž¥ ê°€ê¹Œìš´ ë°”ìš´ë”© ë°•ìŠ¤} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    class_boxes = {}  # {í´ëž˜ìŠ¤ ID: ë°”ìš´ë”© ë°•ìŠ¤ ë¦¬ìŠ¤íŠ¸}

    # YOLO íƒì§€ ê²°ê³¼ë¥¼ í´ëž˜ìŠ¤ë³„ë¡œ ì •ë¦¬
    for result in results:
        for box in result.boxes:
            cls = int(box.cls[0])  # í´ëž˜ìŠ¤ ID ê°€ì ¸ì˜¤ê¸°
            bbox = tuple(map(int, box.xyxy[0]))  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (x1, y1, x2, y2)

            if cls not in class_boxes:
                class_boxes[cls] = []  # í´ëž˜ìŠ¤ IDê°€ ì—†ìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            
            class_boxes[cls].append(bbox)  # í•´ë‹¹ í´ëž˜ìŠ¤ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ê°€

    # í´ëž˜ìŠ¤ë³„ë¡œ ê°€ìž¥ ê°€ê¹Œìš´ ë°”ìš´ë”© ë°•ìŠ¤ë§Œ ë‚¨ê¸°ê¸°
    filtered_roi = {}

    for cls, boxes in class_boxes.items():
        closest_box = get_closest_box_with_depth(boxes, depth_map)  # ê°€ìž¥ ê°€ê¹Œìš´ ê°ì²´ ì„ íƒ
        if closest_box:
            filtered_roi[cls] = closest_box  # í•„í„°ë§ëœ ê²°ê³¼ ì €ìž¥

    return filtered_roi # {í´ëž˜ìŠ¤ ID: ê°€ìž¥ ê°€ê¹Œìš´ ë°”ìš´ë”© ë°•ìŠ¤}


def get_closest_box_with_depth(boxes, depth_map):
    """ Depth Mapì„ ì´ìš©í•´ ê°€ìž¥ ê°€ê¹Œìš´ ë°”ìš´ë”© ë°•ìŠ¤ ì„ íƒ """
    min_depth = float("inf")
    closest_box = None

    for bbox in boxes:
        x1, y1, x2, y2 = bbox

        # ROI(Region of Interest) ì„¤ì •
        roi_depth = depth_map[y1:y2, x1:x2]

        # Depth ê°’ì´ 0ì´ ì•„ë‹Œ ê²ƒë“¤ë§Œ í‰ê·  ê³„ì‚° (ì¼ë¶€ ì„¼ì„œëŠ” 0ì´ ì—†ëŠ” ë°ì´í„°)
        valid_depths = roi_depth[roi_depth > 0]

        if len(valid_depths) > 0:
            avg_depth = np.mean(valid_depths)
            if avg_depth < min_depth:  # ë” ê°€ê¹Œìš´ ê°ì²´ë¼ë©´ ê°±ì‹ 
                min_depth = avg_depth
                closest_box = bbox

    return closest_box


def measure_height(filtered_roi):
    height = {}

    for cls_id in filtered_roi.keys():
        if cls_id == 0:  # ê³„ë‹¨ ë†’ì´ ì¸¡ì •
            bbox = filtered_roi.get(cls_id)
            if bbox:
                height[cls_id] = utils.stairs(bbox)

        elif cls_id == 1:  
            bbox = filtered_roi.get(cls_id)
            if bbox:
                height[cls_id] = utils.some_other_height_function(bbox)

    return height


















#--------ê± í…ŒìŠ¤íŠ¸ìš©-----------



def main():
    model_path = "best.pt"
    image_path = "test.jpg"

    model = YOLO(model_path)  # YOLO ëª¨ë¸ ë¡œë“œ
    results = model(image_path)  # ê°ì²´ íƒì§€ ì‹¤í–‰

    print(results)  # ê²°ê³¼ ì¶œë ¥ (ë””ë²„ê¹…ìš©)

if __name__ == "__main__":
    main()

# -----ì°½ê³ ---------

def draw_bbox(model, image, show = False):
    """
    YOLO ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ê³  ê²°ê³¼ë¥¼ ì¶œë ¥.
    
    Parameters
    ----------
    model : YOLO ê°ì²´
    image : np.ndarray ë˜ëŠ” str
        - np.ndarray: OpenCV ì´ë¯¸ì§€ (BGR)
        - str: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    """
    if isinstance(image, str):
        img = cv2.imread(image)  # íŒŒì¼ ê²½ë¡œì¼ ê²½ìš° ì½ê¸°
    elif isinstance(image, np.ndarray):
        img = image.copy()  # numpy ë°°ì—´ì¼ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
    else:
        raise ValueError("imageëŠ” íŒŒì¼ ê²½ë¡œë‚˜ numpy ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    results = model.predict(img)  # YOLO ì‹¤í–‰
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    
    ##save path
    save_path = "/home/hjkwon/urop-stairs/data/detected.jpg"
    cv2.imwrite(save_path, img)
    print(f"âœ… Bounding box image saved as: {save_path}")

        # ðŸ”¥ Matplotlibìœ¼ë¡œ ì´ë¯¸ì§€ í‘œì‹œ (ì„ íƒ)
    if show:
        plt.figure(figsize=(6, 6))
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title("YOLO Detection")
        plt.axis("off")
        plt.show()